{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrPgiVdCxqET","executionInfo":{"status":"ok","timestamp":1700031943985,"user_tz":-540,"elapsed":26916,"user":{"displayName":"문경","userId":"03211429860722808255"}},"outputId":"6ee78e1b-01aa-4313-d383-093ab45f3017"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bmvdJPVdqC_8","executionInfo":{"status":"ok","timestamp":1700031959234,"user_tz":-540,"elapsed":10178,"user":{"displayName":"문경","userId":"03211429860722808255"}}},"outputs":[],"source":["# 라이브러리\n","import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import albumentations as A\n","from albumentations.pytorch import transforms\n","\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzSXjrJuqDAA","executionInfo":{"status":"ok","timestamp":1700031961531,"user_tz":-540,"elapsed":574,"user":{"displayName":"문경","userId":"03211429860722808255"}},"outputId":"a3b96eee-0c81-4c51-e9e8-18ccab326fba"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["# device setting\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device = torch.device(device)\n","\n","print(device)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"NZ241CP8qDAA","executionInfo":{"status":"ok","timestamp":1700031996919,"user_tz":-540,"elapsed":752,"user":{"displayName":"문경","userId":"03211429860722808255"}}},"outputs":[],"source":["# directory setting\n","class ROOTDIR:\n","    train_dir = '/content/drive/MyDrive/Colab Notebooks/Github/COSE474Project/cityscapes_data/train/'\n","    val_dir = '/content/drive/MyDrive/Colab Notebooks/Github/COSE474Project/cityscapes_data/val/'"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qixjO-t0qDAB","executionInfo":{"status":"ok","timestamp":1700031999608,"user_tz":-540,"elapsed":523,"user":{"displayName":"문경","userId":"03211429860722808255"}},"outputId":"3501a7a5-2c9b-4d0d-c38e-71ebbff48c4c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(790, 0)"]},"metadata":{},"execution_count":5}],"source":["# image file list\n","train_filenames = sorted(glob.glob(ROOTDIR.train_dir+\"*.jpg\"))\n","val_filenames = sorted(glob.glob(ROOTDIR.val_dir+\"*.jpg\"))\n","\n","len(train_filenames), len(val_filenames)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kMfcGtb5qDAB"},"outputs":[],"source":["val_filenames, test_filenames = train_test_split(val_filenames, test_size=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhaBL-CJqDAB"},"outputs":[],"source":["# visualize\n","def show(img_list, train, loop=1):\n","    if train:\n","        dir = ROOTDIR.train_dir\n","    else:\n","        dir = ROOTDIR.val_dir\n","\n","    for i in range(loop):\n","        img_dir = os.path.join(dir, img_list[i])\n","        img = Image.open(img_dir)\n","        print(f\"image path: {dir + img_list[i]}\")\n","        plt.imshow(img)\n","        plt.title(\"image\")\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXFDGRnTqDAC"},"outputs":[],"source":["show(img_list=train_filenames, train=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEPzaKq3qDAD"},"outputs":[],"source":["# Dataset\n","class Cityscape(Dataset):\n","    def __init__(self, img_path, transform=None):\n","        self.img_path = img_path\n","        self.transform = transform\n","\n","    # img list 길이\n","    def __len__(self):\n","        return len(self.img_path)\n","\n","    # get image, label\n","    def __getitem__(self, idx):\n","        data = Image.open(self.img_path[idx]).convert(\"RGB\")\n","        data = np.array(data)\n","\n","        img, label = data[:, :256, :], data[:, 256:, :]\n","\n","        if self.transform:\n","            augmented = self.transform(image = img, mask = label)\n","            img, label = augmented['image'], augmented['mask']\n","            img = torch.from_numpy(img).permute(2, 0, 1)\n","            label = torch.from_numpy(label).permute(2, 0, 1)\n","\n","        return img, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1f6EbliqDAD"},"outputs":[],"source":["# Define Transforms\n","train_Transforms = A.Compose([\n","    A.ElasticTransform(),\n","])\n","\n","val_Transforms = None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eV9zs0byqDAE"},"outputs":[],"source":["# Data Augmentation\n","train_dataset = Cityscape(train_filenames, train_Transforms)\n","val_dataset = Cityscape(val_filenames, val_Transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9az4UeAhqDAE"},"outputs":[],"source":["# Batch\n","batch_size = 16\n","\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, 1, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vpepyF-1qDAE"},"outputs":[],"source":["x, y = next(iter(train_loader))\n","plt.imshow(y[0].permute(1, 2, 0))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"mzKKe0DIqDAE"},"source":["### Build Model ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pmyPi40qDAG"},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(UNet, self).__init__()\n","\n","        self.num_classes = num_classes\n","\n","        # down convolution\n","        self.down_conv_1 = self.convBlock(in_channels=3, out_channels=64)\n","        self.down_conv_2 = self.convBlock(in_channels=64, out_channels=128)\n","        self.down_conv_3 = self.convBlock(in_channels=128, out_channels=256)\n","        self.down_conv_4 = self.convBlock(in_channels=256, out_channels=512)\n","        self.down_conv_5 = self.convBlock(in_channels=512, out_channels=1024)\n","\n","        # Max Pooling\n","        self.maxPool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Dropout\n","        self.dropout = nn.Dropout2d(0.2)\n","\n","        # up convolution transpose\n","        self.up_conv_trans_1 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)\n","        self.up_conv_trans_2 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n","        self.up_conv_trans_3 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n","        self.up_conv_trans_4 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n","\n","        # up convolution\n","        self.up_conv_1 = self.convBlock(in_channels=1024, out_channels=512)\n","        self.up_conv_2 = self.convBlock(in_channels=512, out_channels=256)\n","        self.up_conv_3 = self.convBlock(in_channels=256, out_channels=128)\n","        self.up_conv_4 = self.convBlock(in_channels=128, out_channels=64)\n","\n","        # output\n","        self.output = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n","\n","    def convBlock(self, in_channels, out_channels):\n","        block = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.1),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.1)\n","            )\n","        return block\n","\n","    def padder(self, tensorL, tensorR):\n","        if tensorL.shape != tensorR.shape:\n","            padded = torch.zeros(tensorL.shape)\n","            padded[:, :, :tensorR.shape[2], :tensorR.shape[3]] = tensorR\n","            return padded.to(device)\n","        return tensorR.to(device)\n","\n","    def forward(self, x):\n","        # encoder\n","        x1 = self.down_conv_1(x)\n","        p1 = self.maxPool(x1)\n","        drop1 = self.dropout(p1)\n","        x2 = self.down_conv_2(drop1)\n","        p2 = self.maxPool(x2)\n","        drop2 = self.dropout(p2)\n","        x3 = self.down_conv_3(drop2)\n","        p3 = self.maxPool(x3)\n","        drop3 = self.dropout(p3)\n","        x4 = self.down_conv_4(drop3)\n","        p4 = self.maxPool(x4)\n","        drop5 = self.dropout(p4)\n","        x5 = self.down_conv_5(drop5)\n","\n","        # decoder\n","        d1 = self.up_conv_trans_1(x5)\n","        #print(f\"d1 shape: {d1.shape}\")\n","        concat1 = torch.cat([d1, x4], dim=1)\n","        #print(f\"concat1 shape: {concat1.shape}\")\n","        u1 = self.up_conv_1(concat1)\n","        #print(f\"u1 shape: {u1.shape}\")\n","        d2 = self.up_conv_trans_2(u1)\n","        #print(f\"d2 shape: {d2.shape}\")\n","        concat2 = torch.cat([d2, x3], dim=1)\n","        #print(f\"concat2 shape: {concat2.shape}\")\n","        u2 = self.up_conv_2(concat2)\n","        #print(f\"u2 shape: {u2.shape}\")\n","        d3 = self.up_conv_trans_3(u2)\n","        #print(f\"d3 shape: {d3.shape}\")\n","        concat3 = torch.cat([d3, x2], dim=1)\n","        #print(f\"concat3 shape: {concat3.shape}\")\n","        u3 = self.up_conv_3(concat3)\n","        #print(f\"u3 shape: {u3.shape}\")\n","        d4 = self.up_conv_trans_4(u3)\n","        #print(f\"d4 shape: {d4.shape}\")\n","        concat4 = torch.cat([d4, x1], dim=1)\n","        #print(f\"concat4 shape: {concat4.shape}\")\n","        u4 = self.up_conv_4(concat4)\n","        #print(f\"u4 shape: {u4.shape}\")\n","        output = self.output(u4)\n","        #print(f\"output shape: {output.shape}\")\n","\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"ern9O8ZKqDAG"},"source":["### Train Model ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDkhyzknqDAG"},"outputs":[],"source":["# tensorboard\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjEBpogBqDAG"},"outputs":[],"source":["def dice(pred, target):\n","    pred = (pred > 0).float()\n","    return 2.0 * (pred*target).sum() / (pred+target).sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oV6RBItIqDAH"},"outputs":[],"source":["def train_model(model, dataloader, criterion, optimizer, i):\n","    model.train()\n","    train_running_loss = 0.0\n","    train_running_dice = 0.0\n","\n","    for j, data in enumerate(tqdm(dataloader)):\n","        optimizer.zero_grad()\n","\n","        img = data[0].float().to(device)\n","        mask = data[1].float().to(device)\n","\n","        y_pred = model(img)\n","\n","        loss = criterion(y_pred, mask)\n","\n","        loss.backward()\n","\n","        writer.add_scalar(\"Loss/train\", loss, j+i*len(dataloader))\n","\n","        train_running_loss += loss.item()*batch_size\n","        train_running_dice += dice(y_pred, mask)\n","\n","        optimizer.step()\n","\n","    train_loss = train_running_loss / (j+1)\n","    train_dice = train_running_dice / (j+1)\n","\n","    return train_loss, train_dice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpbqxLsEqDAH"},"outputs":[],"source":["def val_model(model, dataloader, criterion, i):\n","    model.eval()\n","    val_running_loss = 0.0\n","    val_running_dice = 0.0\n","\n","    with torch.no_grad():\n","        for j, data in enumerate(tqdm(dataloader)):\n","            img = data[0].float().to(device)\n","            mask = data[1].float().to(device)\n","\n","            y_pred = model(img)\n","\n","            loss = criterion(y_pred, mask)\n","\n","            writer.add_scalar(\"Loss/validation\", loss, j+i*len(dataloader))\n","\n","            val_running_loss += loss.item()*batch_size\n","            val_running_dice += dice(y_pred, mask)\n","\n","        val_loss = val_running_loss / (j+1)\n","        val_dice = val_running_dice / (j+1)\n","\n","    return val_loss, val_dice, model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZvC62OVqDAH"},"outputs":[],"source":["# Early Stopping\n","class EarlyStopping:\n","    def __init__(self, patience=20, verbose=False, delta=0, trace_func=print):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.val_loss = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.trace_func = trace_func\n","\n","    def __call__(self, val_loss, model, file_name):\n","        if self.val_loss is None:\n","            self.val_loss = val_loss\n","            self.save_checkpoint(val_loss, model, file_name)\n","        elif val_loss > self.val_loss + self.delta:\n","            self.counter += 1\n","            self.trace_func(f\"Early Stopping Counter: {self.counter} out of {self.patience}\")\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.val_loss = val_loss\n","            self.save_checkpoint(val_loss, model, file_name)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, file_name):\n","        if self.verbose:\n","            self.trace_func(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...\")\n","        torch.save(model.state_dict(), file_name)\n","        self.val_loss_min = val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1z6AuW4IqDAH"},"outputs":[],"source":["epochs = 30\n","lr = 0.001\n","num_classes = 3\n","model = UNet(num_classes=num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n","es = EarlyStopping(patience=20, verbose=False, delta=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_a2fiKPfqDAH"},"outputs":[],"source":["train_loss_arr = []\n","train_dice_arr = []\n","val_loss_arr = []\n","val_dice_arr = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uflM0XOJqDAI"},"outputs":[],"source":["for i in tqdm(range(epochs)):\n","    train_loss, train_dice = train_model(model=model, dataloader=train_loader, criterion=criterion, optimizer=optimizer, i=i)\n","    val_loss, val_dice, model = val_model(model=model, dataloader=val_loader, criterion=criterion, i=i)\n","    train_loss_arr.append(train_loss)\n","    train_dice_arr.append(train_dice)\n","    val_loss_arr.append(val_loss)\n","    val_dice_arr.append(val_dice)\n","\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Train Dice score: {train_dice:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(f\"Validation Dice score: {val_dice:.4f}\")\n","\n","    TRAINED_FILE = f\"/home/kmk/DL_final_project/checkpoint/unet_scratch_{i}_epoch.pth\"\n","\n","    es(val_loss, model, TRAINED_FILE)\n","\n","    if es.early_stop:\n","        writer.close()\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkI6YPbSqDAI"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}